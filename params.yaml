preprocess:
  input_dir: data/raw
  output_dir: data/processed
  datasets: [] # ["Beef"]  # or ["GunPoint", "Coffee" ...]
  models: ["kan", "mlp"] # InceptionTime uses MLPs preprocessed data

train_mlp:
  depths: [2] 
  hidden_layers: [50] 
  learning_rates: [0.001]
  seeds: [42]
  epochs: [500]
  batch: 16

train_kan:
  depths: [2] 
  hidden_layers: [20] 
  learning_rates: [0.001]
  epochs: [500]
  batch: 16
  grid: [5] 
  spline_order: 3 

train_inceptiontime:
  depths: [6] 
  learning_rates: [0.001]
  epochs: [500]
  batch: 16
  n_convolutions: [3]
  n_filters: [32]
  kernel_sizes: [32]

train_drtp:
  channels: [[1, 32, 64, 128]]
  fc_layers: [[256, 256, 256]]
  dropouts: [0.2]
  kernel_sizes: [3]
  learning_rates: [0.0001]
  epochs: [500]
  batch: 16

train_noprop:
  Ts: [10]
  emb_dimensions: [0]
  channels: [[1, 32, 64, 128]]
  kernel_sizes: [3]
  fc_layers: [[256, 256, 256]]
  etas: [0.1]
  dropouts: [0.1]
  learning_rates: [0.001]
  weight_decays: [0.001]
  epochs: [70]
  batch: 16